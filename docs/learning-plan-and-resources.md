# Skills Overview (in progress)
## Data engineering Foundations:

- [Data Engineering Foundations](https://www.linkedin.com/learning/data-engineering-foundations/what-is-data-engineering?u=1504)

- [Automating Data Quality in dev environments](https://www.linkedin.com/learning/automating-data-quality-in-dev-environments/why-data-quality-is-crucial?u=1504)

- [synthetic data for software testers](https://www.linkedin.com/learning/synthetic-data-for-software-testers/discover-the-power-of-synthetic-data?u=1504)

- [the-data-analyst-course-complete-data-analyst-bootcamp](https://www.udemy.com/course/the-data-analyst-course-complete-data-analyst-bootcamp/?couponCode=BFCPSALE24)


https://www.linkedin.com/learning/end-to-end-data-engineering-project/transform-complex-data-into-insights?u=1504

https://www.linkedin.com/learning/complete-guide-to-apache-kafka-for-beginners/kafka-course-introduction?u=1504

https://www.linkedin.com/learning/fundamentals-of-apache-iceberg/what-is-data-lakehouse?u=1504

https://www.linkedin.com/learning/learning-hadoop-23008320/what-and-why-hadoop?u=1504


## Python

- [data analysis with python and pandas](https://www.linkedin.com/learning/data-analysis-with-python-and-pandas/course-introduction?u=1504)

- [python for data science and machine learning essential training](https://www.linkedin.com/learning/python-for-data-science-and-machine-learning-essential-training-part-1/data-science-life-hacks?u=1504)

- [hands on data science using sql tableau python and spark](https://www.linkedin.com/learning/hands-on-data-science-using-sql-tableau-python-and-spark/welcome?u=1504)

- [python for data engineering from beginner to advanced](https://www.linkedin.com/learning/python-for-data-engineering-from-beginner-to-advanced/welcome-to-the-course?u=1504)


- [100-days-of-code](https://www.udemy.com/course/100-days-of-code/?couponCode=BFCPSALE24)



## Data Processing

- [big data analytics with hadoop and apache spark](https://www.linkedin.com/learning/big-data-analytics-with-hadoop-and-apache-spark-24658440/the-combined-power-of-spark-and-hadoop-distributed-file-system-hdfs?u=1504)

- [apache spark essential training big data engineering](https://www.linkedin.com/learning/apache-spark-essential-training-big-data-engineering-2021/driving-big-data-engineering-with-apache-spark?u=1504)




## DataOps
- [data engineering pipeline management with apache airflow](https://www.linkedin.com/learning/data-engineering-pipeline-management-with-apache-airflow/features-for-data-engineering-pipeline-management?u=1504)

- [data management with apache nifi](https://www.linkedin.com/learning/data-management-with-apache-nifi/data-management-with-apache-nifi?u=1504)

- [learning-apache-airflow](https://www.linkedin.com/learning/learning-apache-airflow/an-overview-of-apache-airflow?u=1504)



## Databases (SQL,NOSQL)
- [introduction to spark sql and dataframes](https://www.linkedin.com/learning/introduction-to-spark-sql-and-dataframes/apache-spark-sql-and-data-analysis-21043116?u=1504)
- [advanced nosql for data science](https://www.linkedin.com/learning/advanced-nosql-for-data-science/welcome-23229630?u=1504)
- [etl-in-python-and-sql](https://www.linkedin.com/learning/etl-in-python-and-sql/create-an-etl-in-python-and-sql?u=1504)
- [nosql essential training](https://www.linkedin.com/learning/nosql-essential-training/get-to-know-nosql?u=1504)
- [mysql for data engineering](https://www.linkedin.com/learning/mysql-for-data-engineering/hacking-mysql?u=1504)


## Hands-on ETL and Big data test automation tools

### properiatry
- [Informatica Data Validation](https://docs.informatica.com/data-integration/powercenter/10-5/data-validation-option-user-guide/introduction-to-data-validation-option/data-validation-option-overview.html)
- [QuerySurge](https://www.querysurge.com/)
- [ICEDQ](https://icedq.com/)
- [Datagaps ETL Validator](https://www.datagaps.com/etl-validator/)
- [QualiDI](https://www.bitwiseglobal.com/en-us/products/qualidi/)
- [Talend Open Studio for Data Integration](https://www.talend.com/products/talend-open-studio/)
- [Codoid's ETL Testing Services](https://codoid.com/testing-services/big-data/)

### Open Source
- [Data-diff](https://github.com/datafold/data-diff) - A tool for comparing tables within or across databases 
- [Great Expectations](https://github.com/great-expectations/great_expectations) - A data validation and profiling tool written in Python
- [Deeque](https://github.com/awslabs/deequ) - A library based on Apache Spark for measuring data quality in large datasets
- [Pandera](https://github.com/unionai-oss/pandera) - A light-weight, flexible, and expressive statistical data testing library
- [Soda](https://github.com/sodadata/soda-core) - A CLI tool and Python library for data quality testing
- [Datavines](https://github.com/datavane/datavines) - Datavines is Next-gen Data Observability Platform
- [pointblank](https://github.com/rstudio/pointblank) - Data quality assessment and metadata reporting for data frames and database tables
- [DataQualityDashboard](https://github.com/OHDSI/DataQualityDashboard) - A tool to help improve data quality standards in observational data science.
- [dqo](https://github.com/dqops/dqo) - Data Quality and Observability platform for the whole data lifecycle, from profiling new data sources to full automation with Data Observability. Configure data quality checks from the UI or in YAML files, let DQOps run the data quality checks daily to detect data quality issues.
- [YData Profiling](https://docs.profiling.ydata.ai/latest/) -  Data quality profiling and exploratory data analysis are crucial steps in the process of Data Science and Machine Learning development. YData-profiling is a leading tool in the data understanding step of the data science workflow as a pioneering Python package.
- [dbt Core](https://github.com/dbt-labs/dbt-core) - dbt enables data analysts and engineers to transform their data using the same practices that software engineers use to build applications.
- [MobyDQ](https://ubisoft.github.io/mobydq/) - Automate data quality checks on data pipelines
- [Griffin](https://github.com/apache/griffin) - Big Data Quality Solution For Batch and Streaming
- [drunkun data quality](https://github.com/FRosner/drunken-data-quality) - Spark package for checking data quality (not maintained)
- [dataframe rules engine](https://github.com/databrickslabs/dataframe-rules-engine) - Extensible Rules Engine for custom Dataframe / Dataset validation (not maintained)

### Custom framework
TBD