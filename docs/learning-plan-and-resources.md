# Skills
## Data engineering Foundations:

- [Data Engineering Foundations](https://www.linkedin.com/learning/data-engineering-foundations/what-is-data-engineering?u=1504)

- [Automating Data Quality in dev environments](https://www.linkedin.com/learning/automating-data-quality-in-dev-environments/why-data-quality-is-crucial?u=1504)

- [synthetic data for software testers](https://www.linkedin.com/learning/synthetic-data-for-software-testers/discover-the-power-of-synthetic-data?u=1504)

- [the data analyst course complete data analyst bootcamp](https://www.udemy.com/course/the-data-analyst-course-complete-data-analyst-bootcamp/?couponCode=BFCPSALE24)

- [end-to-end data engineering project](https://www.linkedin.com/learning/end-to-end-data-engineering-project/transform-complex-data-into-insights?u=1504)

- [complete guide to apache kafka for beginners](https://www.linkedin.com/learning/complete-guide-to-apache-kafka-for-beginners/kafka-course-introduction?u=1504)

- [fundamentals of apache iceberg](https://www.linkedin.com/learning/fundamentals-of-apache-iceberg/what-is-data-lakehouse?u=1504)

- [learning hadoop](https://www.linkedin.com/learning/learning-hadoop-23008320/what-and-why-hadoop?u=1504)



## Python

- [data analysis with python and pandas](https://www.linkedin.com/learning/data-analysis-with-python-and-pandas/course-introduction?u=1504)

- [python for data science and machine learning essential training](https://www.linkedin.com/learning/python-for-data-science-and-machine-learning-essential-training-part-1/data-science-life-hacks?u=1504)

- [hands on data science using sql tableau python and spark](https://www.linkedin.com/learning/hands-on-data-science-using-sql-tableau-python-and-spark/welcome?u=1504)

- [python for data engineering from beginner to advanced](https://www.linkedin.com/learning/python-for-data-engineering-from-beginner-to-advanced/welcome-to-the-course?u=1504)


- [100 days of code](https://www.udemy.com/course/100-days-of-code/?couponCode=BFCPSALE24)



## Data Processing

- [big data analytics with hadoop and apache spark](https://www.linkedin.com/learning/big-data-analytics-with-hadoop-and-apache-spark-24658440/the-combined-power-of-spark-and-hadoop-distributed-file-system-hdfs?u=1504)

- [apache spark essential training big data engineering](https://www.linkedin.com/learning/apache-spark-essential-training-big-data-engineering-2021/driving-big-data-engineering-with-apache-spark?u=1504)

## DataOps
- [data engineering pipeline management with apache airflow](https://www.linkedin.com/learning/data-engineering-pipeline-management-with-apache-airflow/features-for-data-engineering-pipeline-management?u=1504)

- [data management with apache nifi](https://www.linkedin.com/learning/data-management-with-apache-nifi/data-management-with-apache-nifi?u=1504)

- [learning apache airflow](https://www.linkedin.com/learning/learning-apache-airflow/an-overview-of-apache-airflow?u=1504)

## Databases (SQL,NOSQL)
- [introduction to spark sql and dataframes](https://www.linkedin.com/learning/introduction-to-spark-sql-and-dataframes/apache-spark-sql-and-data-analysis-21043116?u=1504)
- [advanced nosql for data science](https://www.linkedin.com/learning/advanced-nosql-for-data-science/welcome-23229630?u=1504)
- [etl in python and sql](https://www.linkedin.com/learning/etl-in-python-and-sql/create-an-etl-in-python-and-sql?u=1504)
- [nosql essential training](https://www.linkedin.com/learning/nosql-essential-training/get-to-know-nosql?u=1504)
- [mysql for data engineering](https://www.linkedin.com/learning/mysql-for-data-engineering/hacking-mysql?u=1504)

## Hands-on ETL and Big data test automation tools
### proprietary
- [Informatica Data Validation](https://docs.informatica.com/data-integration/powercenter/10-5/data-validation-option-user-guide/introduction-to-data-validation-option/data-validation-option-overview.html)
- [QuerySurge](https://www.querysurge.com/)
- [ICEDQ](https://icedq.com/)
- [Datagaps ETL Validator](https://www.datagaps.com/etl-validator/)
- [QualiDI](https://www.bitwiseglobal.com/en-us/products/qualidi/)
- [Talend Open Studio for Data Integration](https://www.talend.com/products/talend-open-studio/)
- [Codoid's ETL Testing Services](https://codoid.com/testing-services/big-data/)

### Open Source
- [Data-diff](https://github.com/datafold/data-diff) - A tool for comparing tables within or across databases 
- [Great Expectations](https://github.com/great-expectations/great_expectations) - A data validation and profiling tool written in Python
- [Deeque](https://github.com/awslabs/deequ) - A library based on Apache Spark for measuring data quality in large datasets
- [Pandera](https://github.com/unionai-oss/pandera) - A light-weight, flexible, and expressive statistical data testing library
- [Soda](https://github.com/sodadata/soda-core) - A CLI tool and Python library for data quality testing
- [Datavines](https://github.com/datavane/datavines) - Datavines is Next-gen Data Observability Platform
- [pointblank](https://github.com/rstudio/pointblank) - Data quality assessment and metadata reporting for data frames and database tables
- [DataQualityDashboard](https://github.com/OHDSI/DataQualityDashboard) - A tool to help improve data quality standards in observational data science.
- [dqo](https://github.com/dqops/dqo) - Data Quality and Observability platform for the whole data lifecycle, from profiling new data sources to full automation with Data Observability. Configure data quality checks from the UI or in YAML files, let DQOps run the data quality checks daily to detect data quality issues.
- [YData Profiling](https://docs.profiling.ydata.ai/latest/) -  Data quality profiling and exploratory data analysis are crucial steps in the process of Data Science and Machine Learning development. YData-profiling is a leading tool in the data understanding step of the data science workflow as a pioneering Python package.
- [dbt Core](https://github.com/dbt-labs/dbt-core) - dbt enables data analysts and engineers to transform their data using the same practices that software engineers use to build applications.
- [MobyDQ](https://ubisoft.github.io/mobydq/) - Automate data quality checks on data pipelines
- [Griffin](https://github.com/apache/griffin) - Big Data Quality Solution For Batch and Streaming
- [drunkun data quality](https://github.com/FRosner/drunken-data-quality) - Spark package for checking data quality (not maintained)
- [dataframe rules engine](https://github.com/databrickslabs/dataframe-rules-engine) - Extensible Rules Engine for custom Dataframe / Dataset validation (not maintained)

### Custom framework
TBD

# Evaluation
- pass hackerrank python and sql evaulation kit.
- linkedin and udemy courses certificates
- project capstone



| **Stage**         | **Topic**                    | **Tools/Skills**                              | **Resources**                         |
|--------------------|------------------------------|-----------------------------------------------|---------------------------------------|
| **1. Foundation** | Mathematics Basics           | Linear Algebra, Calculus, Statistics          | Khan Academy, 3Blue1Brown            |
|                    | Programming Basics           | Python, R                                     | Codecademy, freeCodeCamp              |
| **2. Data Wrangling** | Data Manipulation           | Pandas, NumPy                                | DataCamp, Kaggle                      |
|                    | Data Cleaning               | Handling Missing Data, Outliers              | Real Python, Towards Data Science     |
| **3. Data Visualization** | Exploratory Data Analysis     | Matplotlib, Seaborn, Plotly                  | Data Viz Courses on Coursera/edX      |
| **4. Databases**   | SQL Basics                  | Querying, Joins, Aggregation                 | SQLZOO, Mode Analytics                |
| **5. Machine Learning** | Supervised Learning          | Regression, Classification                    | scikit-learn Documentation, Coursera  |
|                    | Unsupervised Learning       | Clustering, Dimensionality Reduction         | fast.ai, Udemy                        |
| **6. Advanced Topics** | Deep Learning               | Neural Networks, TensorFlow, PyTorch         | DeepLearning.AI, fast.ai              |
|                    | Natural Language Processing | NLTK, spaCy, Transformers                    | Hugging Face, NLP with Python Book    |
| **7. Deployment**  | Model Deployment            | Flask, Streamlit, Docker                     | YouTube Tutorials, Medium Articles    |
| **8. Practice**    | Real-world Projects         | Kaggle Competitions, Open Data Sets          | Kaggle, UCI ML Repository             |
| **9. Soft Skills** | Communication & Storytelling | PowerPoint, Tableau, Public Speaking         | LinkedIn Learning, Toastmasters       |
| **10. Career Prep**| Building a Portfolio        | GitHub, Blogs, Presentations                 | GitHub Docs, Medium                   |



# Data Warehousing and ETL Learning Track

| **Phase**      | **Topic**                            | **Description**                                                                                   | **Resources**                                                                                       |
|-----------------|--------------------------------------|---------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------|
| **1. Basics**  | Introduction to Data Warehousing     | Learn the fundamentals of data warehousing, its purpose, and use cases.                          | [Introduction to Data Warehousing](https://www.tutorialspoint.com/data_warehouse/index.htm)        |
|                 | Data Warehouse Architecture          | Understand the key components of a data warehouse and its architecture (e.g., star schema).      | [Star Schema vs Snowflake Schema](https://www.dataversity.net)                                      |
|                 | ETL Process Basics                  | Learn the ETL (Extract, Transform, Load) process and its role in data pipelines.                 | [ETL Basics](https://www.educba.com/extract-transform-load/)                                       |
| **2. Tools**   | ETL Tools Overview                   | Get familiar with popular ETL tools (e.g., Talend, Informatica, Apache NiFi).                    | [Top ETL Tools](https://www.guru99.com/etl-tools.html)                                              |
|                 | Data Warehousing Tools              | Explore tools like Snowflake, Amazon Redshift, and Google BigQuery.                              | [Snowflake Documentation](https://docs.snowflake.com/)                                             |
| **3. Design**  | Data Modeling                        | Learn concepts like fact tables, dimension tables, and normalization/denormalization.            | [Data Modeling Basics](https://www.learndatamodeling.com/)                                         |
|                 | Designing ETL Pipelines             | Understand best practices for designing scalable ETL pipelines.                                  | [ETL Pipeline Guide](https://realpython.com/)                                                      |
| **4. Advanced**| Incremental Data Loading             | Explore strategies for loading only new or updated data.                                         | [Incremental Loading Techniques](https://www.sqlshack.com/)                                        |
|                 | Data Quality and Governance         | Learn techniques to ensure data quality and compliance in ETL pipelines.                        | [Data Quality Basics](https://www.dataversity.net/)                                                |
|                 | Performance Tuning                  | Learn how to optimize data warehouses and ETL processes for better performance.                  | [ETL Optimization Guide](https://www.datarevenue.com/en-blog/etl-pipeline-best-practices)          |
| **5. Practice**| Build a Mini Project                 | Implement a small data warehouse with an ETL pipeline using open-source tools.                   | Tutorials from [Kaggle](https://www.kaggle.com/) and [YouTube](https://www.youtube.com/)           |
|                 | Real-World Case Studies             | Study real-world data warehouse implementations to deepen your understanding.                    | [Case Studies](https://aws.amazon.com/solutions/case-studies/)                                     |
| **6. Next Steps** | Certifications                    | Pursue certifications like AWS Certified Data Analytics or Snowflake SnowPro.                    | [Certification Guides](https://www.coursera.org/)                                                  |
|                 | Community Involvement               | Join communities and forums to stay updated and exchange knowledge.                              | [Reddit - Data Engineering](https://www.reddit.com/r/dataengineering/)                             |


Section 1: computer science fundamentals
    - 
Section 2: Building Foundation

Section 3: Core Data Engineering Foundation
